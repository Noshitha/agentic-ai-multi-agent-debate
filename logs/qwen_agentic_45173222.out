Loading cuda version 12.1
==== JOB INFO ====
Job ID: 45173222
Running on node: gypsum-gpu003
Allocated GPUs: 0
Model Path: /project/pi_hongyu_umass_edu/zonghai/sdoh_agentic/models/Qwen3-0.6B
Current working dir: /project/pi_hongyu_umass_edu/zonghai/sdoh_agentic/sdoh-mad-baselines
==================
==== ENV INFO ====
Python 3.12.3
Name: torch
Version: 2.2.2
Name: transformers
Version: 4.57.0
Tue Oct  7 13:56:16 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.169                Driver Version: 570.169        CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla M40 24GB                 On  |   00000000:81:00.0 Off |                    0 |
| N/A   33C    P8             16W /  250W |       0MiB /  23040MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
==================
`torch_dtype` is deprecated! Use `dtype` instead!
2025-10-07 13:56:51.866505: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1759845411.894117 1838095 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1759845411.901719 1838095 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1759845411.922517 1838095 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1759845411.922541 1838095 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1759845411.922546 1838095 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1759845411.922549 1838095 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-10-07 13:56:51.928579: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.

=== Single Agent Baseline ===
Prediction: None
Response: You are an expert clinician analyzing a patient's social history.
Think step-by-step and respond ONLY in this format:
Reasoning: <short reasoning>
Label: <Present | Past | None>

You are given a patient's social history text. Your task is to analyze the text and determine the status of the patient's ...

=== MAD Baseline ===
Final Label: None
Agent 1 predicted: None
Agent 2 predicted: None
Agent 3 predicted: None

Results saved to outputs/qwen3_0.6B/mad_results.json
